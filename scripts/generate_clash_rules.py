#!/usr/bin/env python3
"""å°† custom_routing_rules è‡ªåŠ¨è½¬æ¢ä¸º Clash/mihomo è§„åˆ™æ–‡ä»¶ã€‚"""

from __future__ import annotations

import argparse
import ipaddress
import json
import re
import subprocess
import sys
from dataclasses import dataclass, field
from pathlib import Path
from typing import Iterable

REMARK_TOKEN_MAP = {
    "crack": "crack",
    "bt": "bt",
    "ip": "ip",
    "steam": "steam",
    "åŸŸå": "domain",
    "ç±»åˆ«": "category",
    "ç›´è¿": "direct",
    "ä»£ç†": "proxy",
    "æ‹¦æˆª": "block",
    "å¹¿å‘Š": "ads",
    "ç«¯å£": "port",
    "å…¨éƒ¨": "all",
}

POLICY_MAP = {
    "direct": "direct",
    "proxy": "proxy",
    "block": "block",
}

# v2ray protocol åˆ° Clash çš„å…¼å®¹æ˜ å°„ã€‚
# è¿™é‡Œå±äºâ€œè¯­ä¹‰è¿‘ä¼¼â€è€Œéâ€œè¯­ä¹‰ç­‰ä»·â€ï¼Œå› æ­¤ä¼šåœ¨è¾“å‡ºé‡Œæ˜¾å¼æ ‡æ³¨é£é™©ã€‚
PROTOCOL_FALLBACK_MAP = {
    "bittorrent": "GEOSITE,category-pt",
}


@dataclass
class ConvertedRule:
    index: int
    remarks: str
    enabled: bool
    outbound: str
    provider_name: str
    file_name: str
    payload: list[str]
    is_match_all: bool = False
    notes: list[str] = field(default_factory=list)
    warnings: list[str] = field(default_factory=list)


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="ç”Ÿæˆ Clash/mihomo è‡ªå®šä¹‰è§„åˆ™æ–‡ä»¶")
    parser.add_argument(
        "--input",
        default="custom_routing_rules",
        help="v2ray è§„åˆ™æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šcustom_routing_rulesï¼‰",
    )
    parser.add_argument(
        "--output-dir",
        default="clash",
        help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼šclashï¼‰",
    )
    parser.add_argument(
        "--repo",
        default="",
        help="GitHub ä»“åº“ owner/repoï¼›ä¸ºç©ºæ—¶å°è¯•ä» git remote è‡ªåŠ¨æ¨æ–­",
    )
    parser.add_argument(
        "--branch",
        default="main",
        help="Raw URL ä½¿ç”¨çš„åˆ†æ”¯åï¼ˆé»˜è®¤ï¼šmainï¼‰",
    )
    parser.add_argument(
        "--github-id",
        default="3379345",
        help="ç”¨äº proxy-group icon çš„ GitHub ç”¨æˆ· IDï¼ˆé»˜è®¤ï¼š3379345ï¼‰",
    )
    parser.add_argument(
        "--interval",
        type=int,
        default=86400,
        help="rule-providers åˆ·æ–°å‘¨æœŸç§’æ•°ï¼ˆé»˜è®¤ï¼š86400ï¼‰",
    )
    parser.add_argument(
        "--template-file",
        default="template.fake-ip.yaml",
        help="è®¢é˜…ç«™æ¨¡æ¿è¾“å‡ºæ–‡ä»¶åï¼ˆé»˜è®¤ï¼štemplate.fake-ip.yamlï¼‰",
    )
    parser.add_argument(
        "--no-template",
        action="store_true",
        help="ä¸ç”Ÿæˆè®¢é˜…ç«™æ¨¡æ¿æ–‡ä»¶",
    )
    return parser.parse_args()


def infer_repo_slug(project_root: Path) -> str:
    try:
        result = subprocess.run(
            ["git", "-C", str(project_root), "config", "--get", "remote.origin.url"],
            check=False,
            capture_output=True,
            text=True,
        )
    except FileNotFoundError:
        return ""

    if result.returncode != 0:
        return ""

    return parse_repo_slug_from_url(result.stdout.strip())


def parse_repo_slug_from_url(url: str) -> str:
    # æ”¯æŒï¼š
    # - https://github.com/owner/repo.git
    # - git@github.com:owner/repo.git
    # - https://github.com/owner/repo
    patterns = [
        r"^https://github\.com/([^/]+/[^/.]+?)(?:\.git)?$",
        r"^git@github\.com:([^/]+/[^/.]+?)(?:\.git)?$",
        r"^ssh://git@github\.com/([^/]+/[^/.]+?)(?:\.git)?$",
    ]
    for pattern in patterns:
        match = re.match(pattern, url)
        if match:
            return match.group(1)
    return ""


def load_source_rules(path: Path) -> list[dict]:
    with path.open("r", encoding="utf-8") as fp:
        data = json.load(fp)
    if not isinstance(data, list):
        raise ValueError("æºè§„åˆ™æ–‡ä»¶ä¸æ˜¯ JSON æ•°ç»„")
    return data


def to_slug(remarks: str, used: set[str]) -> str:
    parts: list[str] = []
    for token in re.split(r"[_\s]+", remarks.strip()):
        if not token:
            continue
        mapped = REMARK_TOKEN_MAP.get(token.lower())
        if mapped:
            parts.append(mapped)
            continue
        ascii_part = re.sub(r"[^A-Za-z0-9]+", "-", token).strip("-").lower()
        if ascii_part:
            parts.extend([item for item in ascii_part.split("-") if item])

    slug = "-".join(parts) if parts else "rule"
    if slug not in used:
        used.add(slug)
        return slug

    seq = 2
    while True:
        candidate = f"{slug}-{seq}"
        if candidate not in used:
            used.add(candidate)
            return candidate
        seq += 1


def convert_domain(item: str, warnings: list[str]) -> str:
    if item.startswith("domain:"):
        return f"DOMAIN-SUFFIX,{item[7:]}"
    if item.startswith("full:"):
        return f"DOMAIN,{item[5:]}"
    if item.startswith("keyword:"):
        return f"DOMAIN-KEYWORD,{item[8:]}"
    if item.startswith("regexp:"):
        return f"DOMAIN-REGEX,{item[7:]}"
    if item.startswith("geosite:"):
        return f"GEOSITE,{item[8:]}"
    if item.startswith("ext:"):
        warnings.append(f"ä¸æ”¯æŒçš„ domain æ‰©å±•æ ¼å¼ï¼š{item}")
        return ""
    return f"DOMAIN,{item}"


def convert_ip(item: str, warnings: list[str]) -> str:
    if item.startswith("geoip:"):
        return f"GEOIP,{item[6:]},no-resolve"

    value = item.strip()
    if not value:
        return ""

    try:
        if "/" in value:
            network = ipaddress.ip_network(value, strict=False)
            if network.version == 6:
                return f"IP-CIDR6,{network.with_prefixlen},no-resolve"
            return f"IP-CIDR,{network.with_prefixlen},no-resolve"

        address = ipaddress.ip_address(value)
        if address.version == 6:
            return f"IP-CIDR6,{address.compressed}/128,no-resolve"
        return f"IP-CIDR,{address.compressed}/32,no-resolve"
    except ValueError:
        warnings.append(f"æ— æ³•è§£æ IPï¼Œå·²æŒ‰åŸå€¼é™çº§è¾“å‡ºï¼š{item}")
        return f"IP-CIDR,{value},no-resolve"


def convert_protocol(item: str, notes: list[str], warnings: list[str]) -> str:
    key = item.strip().lower()
    if not key:
        return ""
    if key in PROTOCOL_FALLBACK_MAP:
        # æ˜¾å¼è®°å½•é™çº§åŸå› ï¼Œé˜²æ­¢åç»­ç»´æŠ¤è¯¯è®¤ä¸º 1:1 ç­‰ä»·ã€‚
        notes.append(
            f"v2ray protocol `{item}` åœ¨ Clash æ— ç­‰ä»·å­—æ®µï¼Œä½¿ç”¨ `{PROTOCOL_FALLBACK_MAP[key]}` è¿‘ä¼¼æ˜ å°„ã€‚"
        )
        return PROTOCOL_FALLBACK_MAP[key]

    warnings.append(f"ä¸æ”¯æŒçš„ protocolï¼š{item}")
    return ""


def dedupe_keep_order(items: Iterable[str]) -> list[str]:
    seen: set[str] = set()
    result: list[str] = []
    for item in items:
        if not item or item in seen:
            continue
        seen.add(item)
        result.append(item)
    return result


def is_full_port_range(port_expr: str) -> bool:
    compact = port_expr.replace(" ", "")
    return compact in {"0-65535", "1-65535"}


def convert_rule(index: int, source: dict, used_slugs: set[str]) -> ConvertedRule:
    remarks = str(source.get("remarks", f"rule-{index}"))
    enabled = bool(source.get("enabled", True))
    outbound = str(source.get("outboundTag", "direct")).strip() or "direct"
    notes: list[str] = []
    warnings: list[str] = []
    payload_items: list[str] = []
    is_match_all = False

    for domain_item in source.get("domain", []) or []:
        payload_items.append(convert_domain(str(domain_item), warnings))

    for ip_item in source.get("ip", []) or []:
        payload_items.append(convert_ip(str(ip_item), warnings))

    for protocol_item in source.get("protocol", []) or []:
        payload_items.append(convert_protocol(str(protocol_item), notes, warnings))

    port = str(source.get("port", "")).strip()
    if port:
        if is_full_port_range(port) and not payload_items:
            # çº¯â€œå…¨ç«¯å£å…œåº•â€åœ¨ Clash ä¸­æ›´è§„èŒƒçš„å†™æ³•æ˜¯ MATCHã€‚
            is_match_all = True
            notes.append("å…¨ç«¯å£å…œåº•è§„åˆ™å·²è§„èŒƒåŒ–è½¬æ¢ä¸º MATCHã€‚")
        else:
            payload_items.append(f"DST-PORT,{port}")

    payload = dedupe_keep_order(payload_items)

    if "æ‹¦æˆª" in remarks and outbound == "direct":
        notes.append("remarks å«â€œæ‹¦æˆªâ€ï¼Œä½†åŸè§„åˆ™ outboundTag=directï¼›æŒ‰çœŸå®è¡Œä¸ºè¿ç§»ã€‚")

    if not payload and not is_match_all:
        warnings.append("è¯¥è§„åˆ™æœªç”Ÿæˆä»»ä½• payloadï¼Œè¯·æ‰‹å·¥ç¡®è®¤ã€‚")

    slug = to_slug(remarks, used_slugs)
    file_name = f"{index:02d}-{slug}.yaml"
    provider_name = f"custom-{index:02d}-{slug}"

    return ConvertedRule(
        index=index,
        remarks=remarks,
        enabled=enabled,
        outbound=outbound,
        provider_name=provider_name,
        file_name=file_name,
        payload=payload,
        is_match_all=is_match_all,
        notes=dedupe_keep_order(notes),
        warnings=dedupe_keep_order(warnings),
    )


def write_rule_file(path: Path, rule: ConvertedRule) -> None:
    lines: list[str] = []
    lines.append(f"# ç”± custom_routing_rules ç¬¬ {rule.index} æ¡ï¼ˆ{rule.remarks}ï¼‰è‡ªåŠ¨ç”Ÿæˆã€‚")
    if rule.notes:
        for note in rule.notes:
            lines.append(f"# {note}")
    lines.append("payload:")
    if rule.payload:
        for item in rule.payload:
            lines.append(f"  - {item}")
    else:
        lines.append("  # ç©ºè§„åˆ™ï¼šåŸå§‹æ¡ç›®æ— å¯è¿ç§»åŒ¹é…é¡¹ã€‚")
    path.write_text("\n".join(lines) + "\n", encoding="utf-8")


def write_main_file(
    path: Path,
    rules: list[ConvertedRule],
    repo: str,
    branch: str,
    interval: int,
    github_id: str,
) -> None:
    proxy_group = "ğŸš€ æ‰‹åŠ¨é€‰æ‹©"
    auto_group = "â™»ï¸ è‡ªåŠ¨é€‰æ‹©"
    direct_group = "ğŸ¯ å…¨çƒç›´è¿"
    block_group = "â›” å¼ºåˆ¶é˜»æ–­"
    fallback_group = "ğŸŸ æ¼ç½‘ç­–ç•¥"

    def map_policy_group(outbound: str) -> str:
        if outbound == "proxy":
            return proxy_group
        if outbound == "block":
            return block_group
        return direct_group

    lines: list[str] = []
    lines.append("# åŒ…å«â€œè‡ªå®šä¹‰è§„åˆ™ + é»˜è®¤ç­–ç•¥ç»„â€çš„ä¸»ç‰‡æ®µï¼Œä¸å«èŠ‚ç‚¹ä¸è®¢é˜…é…ç½®ã€‚")
    lines.append("# æœ¬æ–‡ä»¶ç”± scripts/generate_clash_rules.py è‡ªåŠ¨ç”Ÿæˆã€‚")
    lines.append("# è¯´æ˜ï¼š")
    lines.append("# 1) è¯¥æ–‡ä»¶ä¸­çš„åˆ†ç»„å‘½åä¸è®¢é˜…ç«™æ¨¡æ¿ä¿æŒä¸€è‡´ã€‚")
    lines.append("# 2) `ğŸš€ æ‰‹åŠ¨é€‰æ‹©`/`â™»ï¸ è‡ªåŠ¨é€‰æ‹©` é»˜è®¤æ˜¯å¯å¯åŠ¨å…œåº•ï¼Œæ¥å…¥æ—¶è¯·æ›¿æ¢ä¸ºä½ çš„çœŸå®ä»£ç†å…¥å£ã€‚")
    lines.append("")
    lines.append("proxy-groups:")
    lines.append(f"  - name: {proxy_group}")
    lines.append("    type: select")
    lines.append(f"    icon: https://avatars.githubusercontent.com/u/{github_id}?s=128")
    lines.append("    proxies:")
    lines.append(f"      - {auto_group}")
    lines.append(f"      - {direct_group}")
    lines.append(f"  - name: {auto_group}")
    lines.append("    type: select")
    lines.append(f"    icon: https://avatars.githubusercontent.com/u/{github_id}?s=128")
    lines.append("    proxies:")
    lines.append(f"      - {direct_group}")
    lines.append(f"  - name: {direct_group}")
    lines.append("    type: select")
    lines.append(f"    icon: https://avatars.githubusercontent.com/u/{github_id}?s=128")
    lines.append("    proxies:")
    lines.append("      - DIRECT")
    lines.append(f"  - name: {block_group}")
    lines.append("    type: select")
    lines.append(f"    icon: https://avatars.githubusercontent.com/u/{github_id}?s=128")
    lines.append("    proxies:")
    lines.append("      - REJECT")
    lines.append("      - DIRECT")
    lines.append(f"  - name: {fallback_group}")
    lines.append("    type: select")
    lines.append(f"    icon: https://avatars.githubusercontent.com/u/{github_id}?s=128")
    lines.append("    proxies:")
    lines.append(f"      - {direct_group}")
    lines.append(f"      - {proxy_group}")
    lines.append(f"      - {auto_group}")
    lines.append("")
    lines.append("rule-providers:")
    for rule in rules:
        if rule.is_match_all or not rule.enabled:
            continue
        lines.append(f"  {rule.provider_name}:")
        lines.append("    type: http")
        lines.append("    behavior: classical")
        lines.append("    format: yaml")
        lines.append(
            f"    url: https://raw.githubusercontent.com/{repo}/{branch}/clash/rules/{rule.file_name}"
        )
        lines.append(f"    path: ./ruleset/custom/{rule.file_name}")
        lines.append(f"    interval: {interval}")
        lines.append("")

    lines.append("rules:")
    has_terminal_match = False
    for rule in rules:
        policy_group = map_policy_group(rule.outbound)
        lines.append(f"  # {rule.index:02d} {rule.remarks}")
        if rule.is_match_all:
            if not rule.enabled:
                lines.append("  # åŸè§„åˆ™ enabled=falseï¼Œé»˜è®¤ä¿æŒç¦ç”¨ã€‚")
                lines.append(f"  # - MATCH,{fallback_group}")
                continue
            lines.append(f"  - MATCH,{fallback_group}")
            has_terminal_match = True
            continue
        if not rule.enabled:
            lines.append("  # åŸè§„åˆ™ enabled=falseï¼Œé»˜è®¤ä¿æŒç¦ç”¨ã€‚")
            lines.append(f"  # - RULE-SET,{rule.provider_name},{policy_group}")
            continue
        lines.append(f"  - RULE-SET,{rule.provider_name},{policy_group}")

    if not has_terminal_match:
        lines.append(f"  - MATCH,{fallback_group}")
    path.write_text("\n".join(lines) + "\n", encoding="utf-8")


def write_proxy_group_example(path: Path, github_id: str) -> None:
    lines = [
        "# å¯é€‰ç¤ºä¾‹ï¼šä¸è®¢é˜…ç«™æ¨¡æ¿åŒååˆ†ç»„ï¼Œä¾¿äºåœ¨æœ¬åœ°ä¸æ¨¡æ¿ä¹‹é—´ä¿æŒä¸€è‡´è¡Œä¸ºã€‚",
        "# è¯´æ˜ï¼š",
        "# 1) è¿™é‡Œçš„ `ğŸš€ æ‰‹åŠ¨é€‰æ‹©` / `â™»ï¸ è‡ªåŠ¨é€‰æ‹©` æ˜¯å¯å¯åŠ¨å…œåº•ï¼Œè¯·æ›¿æ¢ä¸ºä½ çš„çœŸå®ä»£ç†å…¥å£ã€‚",
        "# 2) `ğŸŸ æ¼ç½‘ç­–ç•¥` ä½œä¸ºæœ«å°¾ MATCH æŒ‡å‘ç»„ï¼Œå¯åœ¨å®¢æˆ·ç«¯ä¸€é”®åˆ‡æ¢ç›´è¿/ä»£ç†ã€‚",
        "# 3) icon ä½¿ç”¨ GitHub å¤´åƒï¼Œä¾¿äºåœ¨ UI è¯†åˆ«è‡ªå®šä¹‰åˆ†ç»„ã€‚",
        "",
        "proxy-groups:",
        "  - name: ğŸš€ æ‰‹åŠ¨é€‰æ‹©",
        "    type: select",
        f"    icon: https://avatars.githubusercontent.com/u/{github_id}?s=128",
        "    proxies:",
        "      - â™»ï¸ è‡ªåŠ¨é€‰æ‹©",
        "      - ğŸ¯ å…¨çƒç›´è¿",
        "",
        "  - name: â™»ï¸ è‡ªåŠ¨é€‰æ‹©",
        "    type: select",
        f"    icon: https://avatars.githubusercontent.com/u/{github_id}?s=128",
        "    proxies:",
        "      - ğŸ¯ å…¨çƒç›´è¿",
        "",
        "  - name: ğŸ¯ å…¨çƒç›´è¿",
        "    type: select",
        f"    icon: https://avatars.githubusercontent.com/u/{github_id}?s=128",
        "    proxies:",
        "      - DIRECT",
        "",
        "  - name: â›” å¼ºåˆ¶é˜»æ–­",
        "    type: select",
        f"    icon: https://avatars.githubusercontent.com/u/{github_id}?s=128",
        "    proxies:",
        "      - REJECT",
        "      - DIRECT",
        "",
        "  - name: ğŸŸ æ¼ç½‘ç­–ç•¥",
        "    type: select",
        f"    icon: https://avatars.githubusercontent.com/u/{github_id}?s=128",
        "    proxies:",
        "      - ğŸ¯ å…¨çƒç›´è¿",
        "      - ğŸš€ æ‰‹åŠ¨é€‰æ‹©",
        "      - â™»ï¸ è‡ªåŠ¨é€‰æ‹©",
    ]
    path.write_text("\n".join(lines) + "\n", encoding="utf-8")


def write_geox_url_snippet(path: Path) -> None:
    lines = [
        "# å¯é€‰ï¼šç»§ç»­æ²¿ç”¨ v2ray-rules-dat ä½œä¸º GEO åŸºç¡€æ•°æ®æºã€‚",
        "# è‹¥ä½ å·²åœ¨ä¸»é…ç½®è®¾ç½® geox-urlï¼Œåˆ™ä»¥ä¸»é…ç½®ä¸ºå‡†ã€‚",
        "",
        "geodata-mode: true",
        "geox-url:",
        "  geoip: https://raw.githubusercontent.com/Loyalsoldier/v2ray-rules-dat/release/geoip.dat",
        "  geosite: https://raw.githubusercontent.com/Loyalsoldier/v2ray-rules-dat/release/geosite.dat",
    ]
    path.write_text("\n".join(lines) + "\n", encoding="utf-8")


def write_readme(path: Path) -> None:
    lines = [
        "# Clash / mihomo è‡ªå®šä¹‰è§„åˆ™è¿ç§»è¯´æ˜",
        "",
        "## è‡ªåŠ¨ç”Ÿæˆå‘½ä»¤",
        "",
        "```bash",
        "python3 scripts/generate_clash_rules.py",
        "```",
        "",
        "å¯é€‰å‚æ•°ç¤ºä¾‹ï¼š",
        "",
        "```bash",
        "python3 scripts/generate_clash_rules.py --repo novcky/v2rayCustomRoutingList --branch main --github-id 3379345",
        "```",
        "",
        "å¦‚éœ€åªç”Ÿæˆè§„åˆ™ç‰‡æ®µï¼Œä¸ç”Ÿæˆè®¢é˜…ç«™æ¨¡æ¿ï¼š",
        "",
        "```bash",
        "python3 scripts/generate_clash_rules.py --no-template",
        "```",
        "",
        "## ç”Ÿæˆç»“æœ",
        "",
        "- `rules/*.yaml`ï¼šæŒ‰ `custom_routing_rules` é¡ºåºæ‹†åˆ†åçš„ rule-provider æ–‡ä»¶ã€‚",
        "- `mihomo-custom-rules.yaml`ï¼šä¸»ç‰‡æ®µï¼ŒåŒ…å« `proxy-groups`ã€`rule-providers` ä¸ `rules`ã€‚",
        "- `template.fake-ip.yaml`ï¼šå¯ç”¨äºè®¢é˜…ç«™æ¸²æŸ“çš„æ¨¡æ¿ï¼ˆå« `__PROXY_PROVIDERS__` / `__PROXY_NODES__` å ä½ç¬¦ï¼‰ã€‚",
        "- `proxy-groups-custom.example.yaml`ï¼šå¯é€‰åˆ†ç»„ç¤ºä¾‹ï¼ˆä¸æ¨¡æ¿åŒåç»„ + iconï¼‰ã€‚",
        "- `geox-url-v2ray-rules-dat.yaml`ï¼šå¯é€‰ GEO æ•°æ®æºç‰‡æ®µã€‚",
        "",
        "## æ¥å…¥å»ºè®®ï¼ˆAndroid / PC é€šç”¨ï¼‰",
        "",
        "1. å°† `mihomo-custom-rules.yaml` åˆå¹¶åˆ°ä¸»é…ç½®ï¼ˆå†…å«ä¸æ¨¡æ¿åŒåçš„é»˜è®¤ç­–ç•¥ç»„ï¼‰ã€‚",
        "2. å°† `ğŸš€ æ‰‹åŠ¨é€‰æ‹©` / `â™»ï¸ è‡ªåŠ¨é€‰æ‹©` æ›¿æ¢ä¸ºä½ çš„çœŸå®ä»£ç†å…¥å£ã€‚",
        "3. å¦‚éœ€ç‹¬ç«‹ç»´æŠ¤ç­–ç•¥ç»„ï¼Œå¯å‚è€ƒ `proxy-groups-custom.example.yaml`ã€‚",
        "4. å¦‚éœ€ç»§ç»­æ²¿ç”¨ v2ray åŸºç¡€åº“ï¼Œå¯åˆå¹¶ `geox-url-v2ray-rules-dat.yaml`ã€‚",
        "",
        "## å…¼å®¹å·®å¼‚",
        "",
        "- `protocol:bittorrent` åœ¨ Clash æ— ç­‰ä»·è§„åˆ™ï¼Œè‡ªåŠ¨é™çº§ä¸º `GEOSITE,category-pt`ã€‚",
        "- çº¯ `0-65535` / `1-65535` å…¨ç«¯å£å…œåº•è§„åˆ™ä¼šè‡ªåŠ¨è½¬æ¢ä¸º `MATCH`ã€‚",
        "- è®¢é˜…ç«™æ¨¡æ¿ä¸­ï¼Œæœ«å°¾ `MATCH` é»˜è®¤æŒ‡å‘â€œæ¼ç½‘ç­–ç•¥â€ç»„ï¼Œä¾¿äºåœ¨å®¢æˆ·ç«¯ä¸€é”®åˆ‡æ¢ç›´è¿/ä»£ç†ã€‚",
        "- `enabled=false` æ¡ç›®ä¸ä¼šç”Ÿæˆ provider æ–‡ä»¶ä¸ provider å£°æ˜ï¼Œä»…ä¿ç•™æ³¨é‡Šæ–¹ä¾¿å›æ»šã€‚",
        "- remarks å†™â€œæ‹¦æˆªâ€ä½† outboundTag ä¸º `direct` çš„æ¡ç›®ï¼Œä¼šæŒ‰çœŸå®è¡Œä¸ºæ˜ å°„ä¸º `direct`ã€‚",
    ]
    path.write_text("\n".join(lines) + "\n", encoding="utf-8")


def write_subscription_template(
    path: Path,
    rules: list[ConvertedRule],
    repo: str,
    branch: str,
    interval: int,
    github_id: str,
) -> None:
    # æ¨¡æ¿é»˜è®¤ä½¿ç”¨å›ºå®šåˆ†ç»„åï¼Œç¡®ä¿è®¢é˜…ç«™æ¸²æŸ“å‰åå‘½åç¨³å®šï¼Œä¸å½±å“è§„åˆ™å¼•ç”¨ã€‚
    proxy_group = "ğŸš€ æ‰‹åŠ¨é€‰æ‹©"
    auto_group = "â™»ï¸ è‡ªåŠ¨é€‰æ‹©"
    direct_group = "ğŸ¯ å…¨çƒç›´è¿"
    block_group = "â›” å¼ºåˆ¶é˜»æ–­"
    fallback_group = "ğŸŸ æ¼ç½‘ç­–ç•¥"

    def map_policy_group(outbound: str) -> str:
        if outbound == "proxy":
            return proxy_group
        if outbound == "block":
            return block_group
        return direct_group

    lines: list[str] = []
    lines.append("# è®¢é˜…ç«™æ¨¡æ¿ï¼šç”± scripts/generate_clash_rules.py è‡ªåŠ¨ç”Ÿæˆã€‚")
    lines.append("# è¯´æ˜ï¼š")
    lines.append("# 1) `__PROXY_PROVIDERS__` ä¸ `__PROXY_NODES__` ç”±è®¢é˜…ç«™åœ¨æ¸²æŸ“é˜¶æ®µæ›¿æ¢ã€‚")
    lines.append("# 2) è‡ªå®šä¹‰è§„åˆ™é¡ºåºæ¥è‡ª custom_routing_rulesï¼Œå¹¶æŒ‰åŸ enabled çŠ¶æ€è¾“å‡ºã€‚")
    lines.append("# 3) æœ«å°¾ MATCH å›ºå®šä½¿ç”¨â€œæ¼ç½‘ç­–ç•¥â€ç»„ï¼Œæ–¹ä¾¿åœ¨å®¢æˆ·ç«¯ä¸€é”®åˆ‡æ¢ç›´è¿/ä»£ç†ã€‚")
    lines.append("")
    lines.append("mode: rule")
    lines.append("dns:")
    lines.append("  enable: true")
    lines.append("  enhanced-mode: fake-ip")
    lines.append("  fake-ip-range: 198.18.0.1/16")
    lines.append("  nameserver:")
    lines.append("    - tls://8.8.8.8")
    lines.append("    - tls://1.1.1.1")
    lines.append("  default-nameserver:")
    lines.append("    - 223.5.5.5")
    lines.append("    - 119.29.29.29")
    lines.append("  nameserver-policy:")
    lines.append("    geosite:cn:")
    lines.append("      - 223.5.5.5")
    lines.append("      - 119.29.29.29")
    lines.append("  fake-ip-filter:")
    lines.append("    - +.lan")
    lines.append("    - +.local")
    lines.append("proxies: null")
    lines.append("proxy-groups:")
    lines.append(f"  - name: {proxy_group}")
    lines.append("    type: select")
    lines.append(f"    icon: https://avatars.githubusercontent.com/u/{github_id}?s=128")
    lines.append("    include-all: true")
    lines.append("    include-all-proxies: true")
    lines.append("    include-all-providers: true")
    lines.append("    proxies:")
    lines.append(f"      - {auto_group}")
    lines.append("      - __PROXY_PROVIDERS__")
    lines.append("      - __PROXY_NODES__")
    lines.append(f"  - name: {auto_group}")
    lines.append("    type: url-test")
    lines.append(f"    icon: https://avatars.githubusercontent.com/u/{github_id}?s=128")
    lines.append("    include-all: true")
    lines.append("    include-all-proxies: true")
    lines.append("    include-all-providers: true")
    lines.append("    proxies:")
    lines.append("      - __PROXY_PROVIDERS__")
    lines.append("      - __PROXY_NODES__")
    lines.append("    url: https://cp.cloudflare.com/generate_204")
    lines.append("    interval: 300")
    lines.append("    tolerance: 50")
    lines.append(f"  - name: {direct_group}")
    lines.append("    type: select")
    lines.append(f"    icon: https://avatars.githubusercontent.com/u/{github_id}?s=128")
    lines.append("    proxies:")
    lines.append("      - DIRECT")
    lines.append(f"  - name: {block_group}")
    lines.append("    type: select")
    lines.append(f"    icon: https://avatars.githubusercontent.com/u/{github_id}?s=128")
    lines.append("    proxies:")
    lines.append("      - REJECT")
    lines.append("      - DIRECT")
    lines.append(f"  - name: {fallback_group}")
    lines.append("    type: select")
    lines.append(f"    icon: https://avatars.githubusercontent.com/u/{github_id}?s=128")
    lines.append("    include-all: true")
    lines.append("    include-all-proxies: true")
    lines.append("    include-all-providers: true")
    lines.append("    proxies:")
    lines.append(f"      - {direct_group}")
    lines.append(f"      - {proxy_group}")
    lines.append(f"      - {auto_group}")
    lines.append("      - __PROXY_PROVIDERS__")
    lines.append("      - __PROXY_NODES__")
    lines.append("rules:")
    has_terminal_match = False
    for rule in rules:
        lines.append(f"  # {rule.index:02d} {rule.remarks}")
        if rule.is_match_all:
            if not rule.enabled:
                lines.append("  # åŸè§„åˆ™ enabled=falseï¼Œé»˜è®¤ä¿æŒç¦ç”¨ã€‚")
                lines.append(f"  # - MATCH,{fallback_group}")
                continue
            lines.append(f"  - MATCH,{fallback_group}")
            has_terminal_match = True
            continue
        if not rule.enabled:
            lines.append("  # åŸè§„åˆ™ enabled=falseï¼Œé»˜è®¤ä¿æŒç¦ç”¨ã€‚")
            lines.append(
                f"  # - RULE-SET,{rule.provider_name},{map_policy_group(rule.outbound)}"
            )
            continue
        lines.append(f"  - RULE-SET,{rule.provider_name},{map_policy_group(rule.outbound)}")
    if not has_terminal_match:
        lines.append(f"  - MATCH,{fallback_group}")
    lines.append("rule-providers:")
    for rule in rules:
        if rule.is_match_all or not rule.enabled:
            continue
        lines.append(f"  {rule.provider_name}:")
        lines.append("    type: http")
        lines.append("    behavior: classical")
        lines.append("    format: yaml")
        lines.append(
            f"    url: https://raw.githubusercontent.com/{repo}/{branch}/clash/rules/{rule.file_name}"
        )
        lines.append(f"    path: ./providers/custom/{rule.file_name}")
        lines.append(f"    interval: {interval}")

    path.write_text("\n".join(lines) + "\n", encoding="utf-8")


def cleanup_generated_rule_files(rules_dir: Path) -> None:
    # ä»…æ¸…ç†â€œåºå·å‰ç¼€â€çš„ç”Ÿæˆäº§ç‰©ï¼Œé¿å…è¯¯åˆ ç”¨æˆ·æ‰‹å·¥ç»´æŠ¤çš„å…¶å®ƒæ–‡ä»¶ã€‚
    pattern = re.compile(r"^\d{2}-.+\.ya?ml$")
    for file_path in rules_dir.glob("*.y*ml"):
        if pattern.match(file_path.name):
            file_path.unlink()


def main() -> int:
    args = parse_args()
    project_root = Path(__file__).resolve().parent.parent
    input_path = (project_root / args.input).resolve()
    output_dir = (project_root / args.output_dir).resolve()

    if not input_path.exists():
        print(f"[ERROR] æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶: {input_path}", file=sys.stderr)
        return 1

    repo = args.repo.strip() or infer_repo_slug(project_root)
    if not repo:
        print(
            "[ERROR] æ— æ³•ä» git remote æ¨æ–­ä»“åº“ï¼Œè¯·é€šè¿‡ --repo owner/repo æ˜¾å¼ä¼ å…¥ã€‚",
            file=sys.stderr,
        )
        return 1

    source_rules = load_source_rules(input_path)

    rules_dir = output_dir / "rules"
    rules_dir.mkdir(parents=True, exist_ok=True)
    cleanup_generated_rule_files(rules_dir)

    used_slugs: set[str] = set()
    converted: list[ConvertedRule] = []
    all_warnings: list[str] = []

    for idx, src_rule in enumerate(source_rules, 1):
        rule = convert_rule(idx, src_rule, used_slugs)
        converted.append(rule)
        if rule.enabled and not rule.is_match_all:
            write_rule_file(rules_dir / rule.file_name, rule)
        for warning in rule.warnings:
            all_warnings.append(f"#{idx:02d} {rule.remarks}: {warning}")

    write_main_file(
        path=output_dir / "mihomo-custom-rules.yaml",
        rules=converted,
        repo=repo,
        branch=args.branch,
        interval=args.interval,
        github_id=args.github_id,
    )
    if not args.no_template:
        write_subscription_template(
            path=output_dir / args.template_file,
            rules=converted,
            repo=repo,
            branch=args.branch,
            interval=args.interval,
            github_id=args.github_id,
        )
    write_proxy_group_example(output_dir / "proxy-groups-custom.example.yaml", args.github_id)
    write_geox_url_snippet(output_dir / "geox-url-v2ray-rules-dat.yaml")
    write_readme(output_dir / "README.md")

    print(f"[OK] å·²ç”Ÿæˆ {len(converted)} æ¡è§„åˆ™åˆ°: {output_dir}")
    if all_warnings:
        print("[WARN] éœ€è¦äººå·¥å…³æ³¨çš„è¿ç§»é¡¹ï¼š", file=sys.stderr)
        for item in all_warnings:
            print(f"  - {item}", file=sys.stderr)

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
