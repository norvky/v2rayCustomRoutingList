#!/usr/bin/env python3
"""å°† custom_routing_rules è‡ªåŠ¨è½¬æ¢ä¸º Clash/mihomo è§„åˆ™æ–‡ä»¶ã€‚"""

from __future__ import annotations

import argparse
import ipaddress
import json
import re
import subprocess
import sys
from dataclasses import dataclass, field
from pathlib import Path
from typing import Iterable

REMARK_TOKEN_MAP = {
    # å°† remarks ä¸­çš„ç¨³å®šè¯å…ƒæ˜ å°„ä¸º ASCII ç‰‡æ®µï¼Œä¿è¯ provider/file åå¯è¯»ä¸”è·¨å¹³å°å…¼å®¹ã€‚
    # æœªæ˜ å°„è¯å…ƒä¼šåœ¨ to_slug ä¸­è¢«å¿½ç•¥ï¼›è‹¥ä¸åŒè§„åˆ™é€€åŒ–åˆ°åŒä¸€ slugï¼Œä¼šè§¦å‘åºå·åç¼€å¹¶å¢åŠ å¼•ç”¨æ¼‚ç§»é£é™©ã€‚
    "crack": "crack",
    "bt": "bt",
    "ip": "ip",
    "steam": "steam",
    "åŸŸå": "domain",
    "ç±»åˆ«": "category",
    "åŒºåŸŸ": "region",
    "ç›´è¿": "direct",
    "ä»£ç†": "proxy",
    "æ‹¦æˆª": "block",
    "å¹¿å‘Š": "ads",
    "ç«¯å£": "port",
    "å…¨éƒ¨": "all",
}

POLICY_MAP = {
    # ç»Ÿä¸€ä¿ç•™ä¸‰ç±»è¯­ä¹‰æ ‡ç­¾ï¼Œä¾¿äºåç»­æ‰©å±•å…¶å®ƒè¾“å‡ºæ¨¡æ¿æ—¶å¤ç”¨ç­–ç•¥æ˜ å°„ã€‚
    "direct": "direct",
    "proxy": "proxy",
    "block": "block",
}

# v2ray protocol åˆ° Clash çš„å…¼å®¹æ˜ å°„ã€‚
# è¿™é‡Œå±äºâ€œè¯­ä¹‰è¿‘ä¼¼â€è€Œéâ€œè¯­ä¹‰ç­‰ä»·â€ï¼Œå› æ­¤ä¼šåœ¨è¾“å‡ºé‡Œæ˜¾å¼æ ‡æ³¨é£é™©ã€‚
PROTOCOL_FALLBACK_MAP = {
    "bittorrent": "GEOSITE,category-pt",
}


@dataclass
class ConvertedRule:
    """å•æ¡æºè§„åˆ™è½¬æ¢åçš„ç»Ÿä¸€ä¸­é—´ç»“æ„ã€‚

    è¿™é‡ŒæŠŠâ€œç”Ÿæˆæ–‡ä»¶å/provider åâ€â€œè§„åˆ™ payloadâ€â€œè¿ç§»å¤‡æ³¨å’Œå‘Šè­¦â€èšåˆåœ¨ä¸€èµ·ï¼Œ
    ç›®çš„æ˜¯è®©åç»­å†™æ–‡ä»¶é˜¶æ®µåªå…³å¿ƒè¾“å‡ºï¼Œä¸å†é‡å¤è§£ææº JSONã€‚
    """

    index: int
    remarks: str
    enabled: bool
    outbound: str
    provider_name: str
    file_name: str
    payload: list[str]
    policy_group: str | None = None
    is_match_all: bool = False
    notes: list[str] = field(default_factory=list)
    warnings: list[str] = field(default_factory=list)


def parse_args() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°ã€‚

    å‚æ•°é»˜è®¤å€¼è¦†ç›–äº†ä»“åº“å¸¸è§ç”¨æ³•ï¼Œä¿è¯åœ¨é¡¹ç›®æ ¹ç›®å½•ç›´æ¥æ‰§è¡Œå³å¯äº§å‡ºå®Œæ•´æ–‡ä»¶ã€‚
    """

    parser = argparse.ArgumentParser(description="ç”Ÿæˆ Clash/mihomo è‡ªå®šä¹‰è§„åˆ™æ–‡ä»¶")
    parser.add_argument(
        "--input",
        default="custom_routing_rules",
        help="v2ray è§„åˆ™æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šcustom_routing_rulesï¼‰",
    )
    parser.add_argument(
        "--output-dir",
        default="clash",
        help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼šclashï¼‰",
    )
    parser.add_argument(
        "--repo",
        default="",
        help="GitHub ä»“åº“ owner/repoï¼›ä¸ºç©ºæ—¶å°è¯•ä» git remote è‡ªåŠ¨æ¨æ–­",
    )
    parser.add_argument(
        "--branch",
        default="main",
        help="Raw URL ä½¿ç”¨çš„åˆ†æ”¯åï¼ˆé»˜è®¤ï¼šmainï¼‰",
    )
    parser.add_argument(
        "--github-id",
        default="3379345",
        help="ç”¨äº proxy-group icon çš„ GitHub ç”¨æˆ· IDï¼ˆé»˜è®¤ï¼š3379345ï¼‰",
    )
    parser.add_argument(
        "--interval",
        type=int,
        default=86400,
        help="rule-providers åˆ·æ–°å‘¨æœŸç§’æ•°ï¼ˆé»˜è®¤ï¼š86400ï¼‰",
    )
    parser.add_argument(
        "--template-file",
        default="template.fake-ip.yaml",
        help="è®¢é˜…ç«™æ¨¡æ¿è¾“å‡ºæ–‡ä»¶åï¼ˆé»˜è®¤ï¼štemplate.fake-ip.yamlï¼‰",
    )
    parser.add_argument(
        "--no-template",
        action="store_true",
        help="ä¸ç”Ÿæˆè®¢é˜…ç«™æ¨¡æ¿æ–‡ä»¶",
    )
    parser.add_argument(
        "--template-profile",
        choices=("compat", "boost"),
        default="compat",
        help="è®¢é˜…ç«™æ¨¡æ¿é…ç½®æ¡£ä½ï¼šcompat(å…¼å®¹ä¼˜å…ˆ)/boost(å¢å¼ºä¼˜å…ˆ)",
    )
    parser.add_argument(
        "--strict",
        action="store_true",
        help="ä¸¥æ ¼æ¨¡å¼ï¼šå‡ºç°ä»»ä½• warning å³è¿”å›é 0",
    )
    return parser.parse_args()


def infer_repo_slug(project_root: Path) -> str:
    """ä» git remote å°è¯•æ¨æ–­ `owner/repo`ã€‚

    å¤±è´¥æ—¶è¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œç”±è°ƒç”¨æ–¹å†³å®šæ˜¯å¦æŠ¥é”™é€€å‡ºï¼Œé¿å…åœ¨è¯¥å‡½æ•°é‡Œæ··å…¥ CLI äº¤äº’é€»è¾‘ã€‚
    """

    try:
        result = subprocess.run(
            ["git", "-C", str(project_root), "config", "--get", "remote.origin.url"],
            check=False,
            capture_output=True,
            text=True,
        )
    except FileNotFoundError:
        return ""

    if result.returncode != 0:
        return ""

    return parse_repo_slug_from_url(result.stdout.strip())


def parse_repo_slug_from_url(url: str) -> str:
    """ä»å¸¸è§ GitHub remote URL æå– `owner/repo`ã€‚

    ä»…åŒ¹é…å·²çŸ¥æ ¼å¼ï¼›æœªåŒ¹é…æ—¶è¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œé¿å…è¯¯è§£æå¯¼è‡´ç”Ÿæˆé”™è¯¯çš„ raw URLã€‚
    """

    # æ”¯æŒï¼š
    # - https://github.com/owner/repo.git
    # - git@github.com:owner/repo.git
    # - https://github.com/owner/repo
    patterns = [
        r"^https://github\.com/([^/]+/[^/.]+?)(?:\.git)?$",
        r"^git@github\.com:([^/]+/[^/.]+?)(?:\.git)?$",
        r"^ssh://git@github\.com/([^/]+/[^/.]+?)(?:\.git)?$",
    ]
    for pattern in patterns:
        match = re.match(pattern, url)
        if match:
            return match.group(1)
    return ""


def load_source_rules(path: Path) -> list[dict]:
    """åŠ è½½å¹¶æ ¡éªŒæºè§„åˆ™ JSONã€‚

    çº¦æŸæºæ–‡ä»¶å¿…é¡»æ˜¯æ•°ç»„ï¼›å¦‚æœç»“æ„å¼‚å¸¸ç›´æ¥æŠ›é”™ï¼Œé˜²æ­¢åç»­é™é»˜ç”Ÿæˆä¸å®Œæ•´è§„åˆ™ã€‚
    """

    with path.open("r", encoding="utf-8") as fp:
        data = json.load(fp)
    if not isinstance(data, list):
        raise ValueError("æºè§„åˆ™æ–‡ä»¶ä¸æ˜¯ JSON æ•°ç»„")
    return data


def validate_source_rules(source_rules: list[dict]) -> tuple[list[str], list[str]]:
    """æ ¡éªŒæºè§„åˆ™ç»“æ„ï¼Œæå‰æš´éœ²é«˜é£é™©é—®é¢˜ã€‚

    è¿™é‡Œä»…åšâ€œç»“æ„æ ¡éªŒ + å…¼å®¹æ€§æ ¡éªŒâ€ï¼Œä¸æ”¹å†™è¾“å…¥å†…å®¹ï¼Œé¿å…é™é»˜ä¿®å¤æ©ç›–é—®é¢˜æ¥æºã€‚
    """

    errors: list[str] = []
    warnings: list[str] = []
    remarks_seen: dict[str, int] = {}
    enabled_match_all_indexes: list[int] = []

    for idx, item in enumerate(source_rules, 1):
        if not isinstance(item, dict):
            errors.append(f"#{idx:02d} è§„åˆ™ä¸æ˜¯å¯¹è±¡ï¼Œå®é™…ç±»å‹ä¸º `{type(item).__name__}`ã€‚")
            continue

        remarks = str(item.get("remarks", f"rule-{idx}")).strip() or f"rule-{idx}"
        if remarks in remarks_seen:
            warnings.append(
                f"#{idx:02d} ä¸ #{remarks_seen[remarks]:02d} çš„ remarks åŒåï¼š`{remarks}`ã€‚"
            )
        else:
            remarks_seen[remarks] = idx

        outbound_raw = str(item.get("outboundTag", "direct")).strip()
        outbound = outbound_raw.lower()
        if outbound and outbound not in POLICY_MAP:
            warnings.append(
                f"#{idx:02d} `{remarks}` çš„ outboundTag=`{outbound_raw}` æœªè¯†åˆ«ï¼Œå°†å›è½ä¸º directã€‚"
            )

        for list_key in ("domain", "ip", "protocol"):
            if list_key in item and item[list_key] is not None and not isinstance(
                item[list_key], list
            ):
                errors.append(
                    f"#{idx:02d} `{remarks}` çš„ `{list_key}` å¿…é¡»æ˜¯æ•°ç»„æˆ– nullã€‚"
                )

        if "policyGroup" in item and item["policyGroup"] is not None and not isinstance(
            item["policyGroup"], str
        ):
            errors.append(f"#{idx:02d} `{remarks}` çš„ `policyGroup` å¿…é¡»æ˜¯å­—ç¬¦ä¸²æˆ– nullã€‚")

        enabled_raw = item.get("enabled", True)
        if not isinstance(enabled_raw, bool):
            warnings.append(
                f"#{idx:02d} `{remarks}` çš„ enabled éå¸ƒå°”å€¼ï¼Œå°†æŒ‰ Python bool è§„åˆ™å¤„ç†ã€‚"
            )

        port_raw = item.get("port", "")
        if port_raw is None:
            port = ""
        elif isinstance(port_raw, (str, int)):
            port = str(port_raw).strip()
        else:
            errors.append(f"#{idx:02d} `{remarks}` çš„ `port` å¿…é¡»æ˜¯å­—ç¬¦ä¸²/æ•°å­—/nullã€‚")
            port = ""

        has_domain = bool(item.get("domain"))
        has_ip = bool(item.get("ip"))
        has_protocol = bool(item.get("protocol"))
        if bool(enabled_raw) and is_full_port_range(port) and not (
            has_domain or has_ip or has_protocol
        ):
            enabled_match_all_indexes.append(idx)

    if len(enabled_match_all_indexes) > 1:
        warnings.append(
            "å­˜åœ¨å¤šæ¡å·²å¯ç”¨â€œå…¨ç«¯å£å…œåº•â€è§„åˆ™ï¼Œåå‡ºç°çš„ MATCH ä¼šé®è”½å‰è€…ï¼š"
            + ", ".join(f"#{idx:02d}" for idx in enabled_match_all_indexes)
        )

    return errors, warnings


def to_slug(remarks: str, used: set[str]) -> str:
    """å°† remarks è½¬æ¢ä¸º provider/file ä½¿ç”¨çš„ slugã€‚

    è®¾è®¡ç›®æ ‡ï¼š
    1) å°½é‡ä¿ç•™è¯­ä¹‰å¯è¯»æ€§ï¼Œä¾¿äºæ’éšœæ—¶ä»æ–‡ä»¶ååæ¨æ¥æºè§„åˆ™ï¼›
    2) åœ¨åç§°å†²çªæ—¶ç¨³å®šè¿½åŠ åºå·ï¼Œé¿å…è¦†ç›–å·²æœ‰ç”Ÿæˆç‰©ã€‚
    """

    parts: list[str] = []
    for token in re.split(r"[_\s]+", remarks.strip()):
        if not token:
            continue
        mapped = REMARK_TOKEN_MAP.get(token.lower())
        if mapped:
            parts.append(mapped)
            continue
        ascii_part = re.sub(r"[^A-Za-z0-9]+", "-", token).strip("-").lower()
        if ascii_part:
            parts.extend([item for item in ascii_part.split("-") if item])

    # å½“ remarks å«æœªçŸ¥ä¸­æ–‡è¯å…ƒæ—¶ï¼Œå¯èƒ½å¾—åˆ°ç©º/é‡å¤ slugï¼›è¿™é‡Œä¿åº•ä¸º rule å¹¶åœ¨å†²çªæ—¶è¿½åŠ åºå·ã€‚
    slug = "-".join(parts) if parts else "rule"
    if slug not in used:
        used.add(slug)
        return slug

    seq = 2
    while True:
        candidate = f"{slug}-{seq}"
        if candidate not in used:
            used.add(candidate)
            return candidate
        seq += 1


def convert_domain(item: str, warnings: list[str]) -> str:
    """å°† v2ray domain æ¡ç›®è½¬æ¢ä¸º Clash classical è§„åˆ™ã€‚"""

    if item.startswith("domain:"):
        return f"DOMAIN-SUFFIX,{item[7:]}"
    if item.startswith("full:"):
        return f"DOMAIN,{item[5:]}"
    if item.startswith("keyword:"):
        return f"DOMAIN-KEYWORD,{item[8:]}"
    if item.startswith("regexp:"):
        return f"DOMAIN-REGEX,{item[7:]}"
    if item.startswith("geosite:"):
        return f"GEOSITE,{item[8:]}"
    if item.startswith("ext:"):
        warnings.append(f"ä¸æ”¯æŒçš„ domain æ‰©å±•æ ¼å¼ï¼š{item}")
        return ""
    return f"DOMAIN,{item}"


def convert_ip(item: str, warnings: list[str]) -> str:
    """å°† v2ray IP/geoip æ¡ç›®è½¬æ¢ä¸º Clash classical è§„åˆ™ã€‚

    è§£æå¤±è´¥æ—¶ä¼šé™çº§ä¿ç•™åŸå€¼å¹¶å†™å…¥ warningï¼Œé¿å…å› å•æ¡è„æ•°æ®ä¸­æ–­æ•´æ‰¹ç”Ÿæˆã€‚
    """

    if item.startswith("geoip:"):
        return f"GEOIP,{item[6:]},no-resolve"

    value = item.strip()
    if not value:
        return ""

    try:
        if "/" in value:
            network = ipaddress.ip_network(value, strict=False)
            if network.version == 6:
                return f"IP-CIDR6,{network.with_prefixlen},no-resolve"
            return f"IP-CIDR,{network.with_prefixlen},no-resolve"

        address = ipaddress.ip_address(value)
        if address.version == 6:
            return f"IP-CIDR6,{address.compressed}/128,no-resolve"
        return f"IP-CIDR,{address.compressed}/32,no-resolve"
    except ValueError:
        warnings.append(f"æ— æ³•è§£æ IPï¼Œå·²æŒ‰åŸå€¼é™çº§è¾“å‡ºï¼š{item}")
        return f"IP-CIDR,{value},no-resolve"


def convert_protocol(item: str, notes: list[str], warnings: list[str]) -> str:
    """å°† v2ray protocol æ¡ç›®è½¬æ¢ä¸º Clash å¯è¡¨è¾¾çš„è¿‘ä¼¼è§„åˆ™ã€‚"""

    key = item.strip().lower()
    if not key:
        return ""
    if key in PROTOCOL_FALLBACK_MAP:
        # æ˜¾å¼è®°å½•é™çº§åŸå› ï¼Œé˜²æ­¢åç»­ç»´æŠ¤è¯¯è®¤ä¸º 1:1 ç­‰ä»·ã€‚
        notes.append(
            f"v2ray protocol `{item}` åœ¨ Clash æ— ç­‰ä»·å­—æ®µï¼Œä½¿ç”¨ `{PROTOCOL_FALLBACK_MAP[key]}` è¿‘ä¼¼æ˜ å°„ã€‚"
        )
        return PROTOCOL_FALLBACK_MAP[key]

    warnings.append(f"ä¸æ”¯æŒçš„ protocolï¼š{item}")
    return ""


def dedupe_keep_order(items: Iterable[str]) -> list[str]:
    """æŒ‰é¦–æ¬¡å‡ºç°é¡ºåºå»é‡ã€‚

    è§„åˆ™é¡ºåºä¼šå½±å“å‘½ä¸­è¡Œä¸ºï¼Œå› æ­¤ä¸èƒ½ä½¿ç”¨ä¼šæ‰“ä¹±é¡ºåºçš„å»é‡æ–¹å¼ã€‚
    """

    seen: set[str] = set()
    result: list[str] = []
    for item in items:
        if not item or item in seen:
            continue
        seen.add(item)
        result.append(item)
    return result


def is_full_port_range(port_expr: str) -> bool:
    """åˆ¤æ–­ç«¯å£è¡¨è¾¾å¼æ˜¯å¦ä¸ºå…¨ç«¯å£èŒƒå›´ã€‚"""

    compact = port_expr.replace(" ", "")
    return compact in {"0-65535", "1-65535"}


def convert_rule(index: int, source: dict, used_slugs: set[str]) -> ConvertedRule:
    """å°†å•æ¡æºè§„åˆ™è½¬æ¢ä¸º `ConvertedRule`ã€‚

    è¿™é‡Œé›†ä¸­å¤„ç† domain/ip/protocol/port å››ç±»åŒ¹é…é¡¹ï¼Œå¹¶äº§å‡º notes/warningsï¼Œ
    è®©å†™æ–‡ä»¶é˜¶æ®µåªåšçº¯è¾“å‡ºæ‹¼è£…ã€‚
    """

    remarks = str(source.get("remarks", f"rule-{index}"))
    enabled = bool(source.get("enabled", True))
    outbound = (str(source.get("outboundTag", "direct")).strip() or "direct").lower()
    notes: list[str] = []
    warnings: list[str] = []
    payload_items: list[str] = []
    is_match_all = False
    policy_group: str | None = None

    # éé¢„æœŸç­–ç•¥å€¼ç»Ÿä¸€å›è½åˆ° directï¼Œä¿è¯ç”Ÿæˆé…ç½®å¯åŠ è½½ã€‚
    if outbound not in POLICY_MAP:
        warnings.append(f"æœªè¯†åˆ«çš„ outboundTag=`{outbound}`ï¼Œå·²å›è½åˆ° directã€‚")
        outbound = "direct"

    policy_group_raw = source.get("policyGroup")
    if policy_group_raw is not None:
        if isinstance(policy_group_raw, str):
            normalized_group = policy_group_raw.strip()
            if normalized_group:
                policy_group = normalized_group
            else:
                warnings.append("policyGroup ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œå·²å¿½ç•¥ã€‚")
        else:
            warnings.append("policyGroup ä¸æ˜¯å­—ç¬¦ä¸²ï¼Œå·²å¿½ç•¥ã€‚")

    # `or []` ç”¨äºå®¹é”™ nullï¼Œé¿å…å†å²æ•°æ®å†™æˆ `domain: null` æ—¶æŠ›å¼‚å¸¸ã€‚
    for domain_item in source.get("domain", []) or []:
        payload_items.append(convert_domain(str(domain_item), warnings))

    for ip_item in source.get("ip", []) or []:
        payload_items.append(convert_ip(str(ip_item), warnings))

    for protocol_item in source.get("protocol", []) or []:
        payload_items.append(convert_protocol(str(protocol_item), notes, warnings))

    # ç«¯å£è§„åˆ™åœ¨ v2ray ä¸ Clash çš„æœ€ä½³å®è·µä¸åŒï¼šå…¨ç«¯å£å…œåº•ç»Ÿä¸€å½’ä¸€åŒ–ä¸º MATCHã€‚
    port = str(source.get("port", "")).strip()
    if port:
        if is_full_port_range(port) and not payload_items:
            # çº¯â€œå…¨ç«¯å£å…œåº•â€åœ¨ Clash ä¸­æ›´è§„èŒƒçš„å†™æ³•æ˜¯ MATCHã€‚
            is_match_all = True
            notes.append("å…¨ç«¯å£å…œåº•è§„åˆ™å·²è§„èŒƒåŒ–è½¬æ¢ä¸º MATCHã€‚")
        else:
            payload_items.append(f"DST-PORT,{port}")

    payload = dedupe_keep_order(payload_items)

    # æ˜¾å¼æç¤ºâ€œå‘½åè¯­ä¹‰â€å’Œâ€œçœŸå®ç­–ç•¥â€ä¸ä¸€è‡´ï¼Œé™ä½åç»­ç»´æŠ¤è¯¯åˆ¤æ¦‚ç‡ã€‚
    if "æ‹¦æˆª" in remarks and outbound == "direct":
        notes.append("remarks å«â€œæ‹¦æˆªâ€ï¼Œä½†åŸè§„åˆ™ outboundTag=directï¼›æŒ‰çœŸå®è¡Œä¸ºè¿ç§»ã€‚")

    if not payload and not is_match_all:
        warnings.append("è¯¥è§„åˆ™æœªç”Ÿæˆä»»ä½• payloadï¼Œè¯·æ‰‹å·¥ç¡®è®¤ã€‚")

    slug = to_slug(remarks, used_slugs)
    file_name = f"{index:02d}-{slug}.yaml"
    provider_name = f"custom-{index:02d}-{slug}"

    return ConvertedRule(
        index=index,
        remarks=remarks,
        enabled=enabled,
        outbound=outbound,
        provider_name=provider_name,
        file_name=file_name,
        payload=payload,
        policy_group=policy_group,
        is_match_all=is_match_all,
        notes=dedupe_keep_order(notes),
        warnings=dedupe_keep_order(warnings),
    )


def collect_custom_policy_groups(rules: list[ConvertedRule], builtins: set[str]) -> list[str]:
    """æ”¶é›†ç”± `custom_routing_rules.policyGroup` å£°æ˜çš„æ‰©å±•åˆ†ç»„ã€‚

    ä»…è¿”å›â€œéå†…ç½®åˆ†ç»„ä¸”é direct/proxy/block åˆ«åâ€çš„åç§°ï¼Œä¿æŒé¦–æ¬¡å‡ºç°é¡ºåºã€‚
    """

    custom_groups: list[str] = []
    seen: set[str] = set()
    alias_keys = {"direct", "proxy", "block"}
    for rule in rules:
        if not rule.policy_group:
            continue
        group_name = rule.policy_group.strip()
        if not group_name:
            continue
        if group_name in builtins:
            continue
        if group_name.lower() in alias_keys:
            continue
        if group_name in seen:
            continue
        seen.add(group_name)
        custom_groups.append(group_name)
    return custom_groups


def resolve_policy_group(
    rule: ConvertedRule,
    proxy_group: str,
    direct_group: str,
    block_group: str,
) -> str:
    """è§£æå•æ¡è§„åˆ™æœ€ç»ˆæ˜ å°„åˆ°çš„ç­–ç•¥ç»„åã€‚"""

    alias_map = {
        "proxy": proxy_group,
        "direct": direct_group,
        "block": block_group,
    }

    if rule.policy_group:
        group_name = rule.policy_group.strip()
        if group_name:
            mapped = alias_map.get(group_name.lower())
            return mapped if mapped else group_name

    if rule.outbound == "proxy":
        return proxy_group
    if rule.outbound == "block":
        return block_group
    return direct_group


def write_rule_file(path: Path, rule: ConvertedRule) -> None:
    """å†™å…¥å•æ¡ rule-provider æ–‡ä»¶ã€‚"""

    lines: list[str] = []
    lines.append(f"# ç”± custom_routing_rules ç¬¬ {rule.index} æ¡ï¼ˆ{rule.remarks}ï¼‰è‡ªåŠ¨ç”Ÿæˆã€‚")
    if rule.notes:
        for note in rule.notes:
            lines.append(f"# {note}")
    lines.append("payload:")
    if rule.payload:
        for item in rule.payload:
            lines.append(f"  - {item}")
    else:
        lines.append("  # ç©ºè§„åˆ™ï¼šåŸå§‹æ¡ç›®æ— å¯è¿ç§»åŒ¹é…é¡¹ã€‚")
    path.write_text("\n".join(lines) + "\n", encoding="utf-8")


def write_main_file(
    path: Path,
    rules: list[ConvertedRule],
    repo: str,
    branch: str,
    interval: int,
    github_id: str,
) -> None:
    """ç”Ÿæˆ `mihomo-custom-rules.yaml` ä¸»ç‰‡æ®µã€‚

    æ–‡ä»¶ç›®æ ‡æ˜¯â€œå¯ç›´æ¥å¹¶å…¥ä¸»é…ç½®â€ï¼Œå› æ­¤åŒæ—¶è¾“å‡ºç­–ç•¥ç»„ã€provider å£°æ˜å’Œè§„åˆ™é¡ºåºã€‚
    """

    # å‚æ•°ä¿ç•™ï¼šå½“å‰ä¸»ç‰‡æ®µæœªä½¿ç”¨å›¾æ ‡å­—æ®µï¼Œä½†ä¿æŒç­¾åä¸€è‡´å¯å‡å°‘æœªæ¥æ¨¡æ¿åˆå¹¶æˆæœ¬ã€‚
    _ = github_id
    proxy_group = "ğŸš€ æ‰‹åŠ¨é€‰æ‹©"
    auto_group = "â™»ï¸ è‡ªåŠ¨é€‰æ‹©"
    direct_group = "ğŸ¯ å…¨çƒç›´è¿"
    block_group = "â›” å¼ºåˆ¶é˜»æ–­"
    fallback_group = "ğŸŸ æ¼ç½‘ç­–ç•¥"

    builtin_groups = {proxy_group, auto_group, direct_group, block_group, fallback_group}
    custom_policy_groups = collect_custom_policy_groups(rules, builtin_groups)

    lines: list[str] = []
    lines.append("# åŒ…å«â€œè‡ªå®šä¹‰è§„åˆ™ + é»˜è®¤ç­–ç•¥ç»„â€çš„ä¸»ç‰‡æ®µï¼Œä¸å«èŠ‚ç‚¹ä¸è®¢é˜…é…ç½®ã€‚")
    lines.append("# æœ¬æ–‡ä»¶ç”± scripts/generate_clash_rules.py è‡ªåŠ¨ç”Ÿæˆã€‚")
    lines.append("# è¯´æ˜ï¼š")
    lines.append("# 1) è¯¥æ–‡ä»¶ä¸­çš„åˆ†ç»„å‘½åä¸è®¢é˜…ç«™æ¨¡æ¿ä¿æŒä¸€è‡´ã€‚")
    lines.append("# 2) `ğŸš€ æ‰‹åŠ¨é€‰æ‹©`/`â™»ï¸ è‡ªåŠ¨é€‰æ‹©` é»˜è®¤æ˜¯å¯å¯åŠ¨å…œåº•ï¼Œæ¥å…¥æ—¶è¯·æ›¿æ¢ä¸ºä½ çš„çœŸå®ä»£ç†å…¥å£ã€‚")
    lines.append("")
    lines.append("proxy-groups:")
    lines.append(f"  - name: {proxy_group}")
    lines.append("    type: select")
    lines.append("    proxies:")
    lines.append(f"      - {auto_group}")
    lines.append(f"      - {direct_group}")
    lines.append(f"  - name: {auto_group}")
    lines.append("    type: select")
    lines.append("    proxies:")
    lines.append(f"      - {direct_group}")
    lines.append(f"  - name: {direct_group}")
    lines.append("    type: select")
    lines.append("    proxies:")
    lines.append("      - DIRECT")
    lines.append(f"  - name: {block_group}")
    lines.append("    type: select")
    lines.append("    proxies:")
    lines.append("      - REJECT")
    lines.append("      - DIRECT")
    for group_name in custom_policy_groups:
        # æ‰©å±•åˆ†ç»„ç”± custom_routing_rules çš„ policyGroup å£°æ˜é©±åŠ¨ï¼Œé¿å…æ¨¡æ¿å†…å†™æ­»ä¸šåŠ¡åˆ†ç»„ã€‚
        lines.append(f"  - name: {group_name}")
        lines.append("    type: select")
        lines.append("    proxies:")
        lines.append(f"      - {proxy_group}")
        lines.append(f"      - {auto_group}")
        lines.append(f"      - {direct_group}")
        lines.append(f"      - {block_group}")
    lines.append(f"  - name: {fallback_group}")
    lines.append("    type: select")
    lines.append("    proxies:")
    lines.append(f"      - {direct_group}")
    lines.append(f"      - {proxy_group}")
    lines.append(f"      - {auto_group}")
    lines.append("")
    # å…ˆå†™ provider å£°æ˜ï¼Œä¾¿äºé˜…è¯»æ—¶å…ˆçœ‹åˆ°â€œä¾èµ–äº†å“ªäº›è§„åˆ™æ–‡ä»¶â€ã€‚
    lines.append("rule-providers:")
    for rule in rules:
        if rule.is_match_all or not rule.enabled:
            continue
        lines.append(f"  {rule.provider_name}:")
        lines.append("    type: http")
        lines.append("    behavior: classical")
        lines.append("    format: yaml")
        lines.append(
            f"    url: https://raw.githubusercontent.com/{repo}/{branch}/clash/rules/{rule.file_name}"
        )
        lines.append(f"    path: ./ruleset/custom/{rule.file_name}")
        lines.append(f"    interval: {interval}")
        lines.append("")

    lines.append("rules:")
    has_terminal_match = False
    for rule in rules:
        policy_group = resolve_policy_group(rule, proxy_group, direct_group, block_group)
        lines.append(f"  # {rule.index:02d} {rule.remarks}")
        if rule.is_match_all:
            # MATCH æ˜¯ç»ˆæ­¢å‹è§„åˆ™ï¼›åªå…è®¸ä¿ç•™æœ€åä¸€æ¬¡å¯ç”¨ç»“æœã€‚
            if not rule.enabled:
                lines.append("  # åŸè§„åˆ™ enabled=falseï¼Œé»˜è®¤ä¿æŒç¦ç”¨ã€‚")
                lines.append(f"  # - MATCH,{fallback_group}")
                continue
            lines.append(f"  - MATCH,{fallback_group}")
            has_terminal_match = True
            continue
        if not rule.enabled:
            # disabled æ¡ç›®ä¿ç•™ä¸ºæ³¨é‡Šï¼Œä¾¿äºå›æ»šæ—¶ç›´æ¥å–æ¶ˆæ³¨é‡Šæ¢å¤ã€‚
            lines.append("  # åŸè§„åˆ™ enabled=falseï¼Œé»˜è®¤ä¿æŒç¦ç”¨ã€‚")
            lines.append(f"  # - RULE-SET,{rule.provider_name},{policy_group}")
            continue
        lines.append(f"  - RULE-SET,{rule.provider_name},{policy_group}")

    if not has_terminal_match:
        # é˜²å¾¡å¼å…œåº•ï¼šæºè§„åˆ™è‹¥æœªåŒ…å«å…¨ç«¯å£/å…¨æµé‡å…œåº•ï¼Œè‡ªåŠ¨è¡¥ä¸€ä¸ª MATCHã€‚
        lines.append(f"  - MATCH,{fallback_group}")
    path.write_text("\n".join(lines) + "\n", encoding="utf-8")


def write_proxy_group_example(path: Path, github_id: str) -> None:
    """ç”Ÿæˆç‹¬ç«‹çš„ç­–ç•¥ç»„ç¤ºä¾‹æ–‡ä»¶ã€‚"""

    # å‚æ•°ä¿ç•™ï¼šç¤ºä¾‹æ–‡ä»¶æš‚æœªå†™å…¥ icon å­—æ®µï¼Œåç»­å¦‚éœ€æ¥å…¥å¯ç›´æ¥å¤ç”¨è°ƒç”¨ç­¾åã€‚
    _ = github_id
    # è¿™é‡Œè¾“å‡ºçš„æ˜¯â€œæœ€å°å¯å¯åŠ¨åˆ†ç»„â€ï¼Œä¾¿äºç”¨æˆ·åœ¨ä¸åŒè®¢é˜…æ¨¡æ¿ä¹‹é—´å¤ç”¨å‘½åã€‚
    lines = [
        "# å¯é€‰ç¤ºä¾‹ï¼šä¸è®¢é˜…ç«™æ¨¡æ¿åŒååˆ†ç»„ï¼Œä¾¿äºåœ¨æœ¬åœ°ä¸æ¨¡æ¿ä¹‹é—´ä¿æŒä¸€è‡´è¡Œä¸ºã€‚",
        "# è¯´æ˜ï¼š",
        "# 1) è¿™é‡Œçš„ `ğŸš€ æ‰‹åŠ¨é€‰æ‹©` / `â™»ï¸ è‡ªåŠ¨é€‰æ‹©` æ˜¯å¯å¯åŠ¨å…œåº•ï¼Œè¯·æ›¿æ¢ä¸ºä½ çš„çœŸå®ä»£ç†å…¥å£ã€‚",
        "# 2) `ğŸŸ æ¼ç½‘ç­–ç•¥` ä½œä¸ºæœ«å°¾ MATCH æŒ‡å‘ç»„ï¼Œå¯åœ¨å®¢æˆ·ç«¯ä¸€é”®åˆ‡æ¢ç›´è¿/ä»£ç†ã€‚",
        "",
        "proxy-groups:",
        "  - name: ğŸš€ æ‰‹åŠ¨é€‰æ‹©",
        "    type: select",
        "    proxies:",
        "      - â™»ï¸ è‡ªåŠ¨é€‰æ‹©",
        "      - ğŸ¯ å…¨çƒç›´è¿",
        "",
        "  - name: â™»ï¸ è‡ªåŠ¨é€‰æ‹©",
        "    type: select",
        "    proxies:",
        "      - ğŸ¯ å…¨çƒç›´è¿",
        "",
        "  - name: ğŸ¯ å…¨çƒç›´è¿",
        "    type: select",
        "    proxies:",
        "      - DIRECT",
        "",
        "  - name: â›” å¼ºåˆ¶é˜»æ–­",
        "    type: select",
        "    proxies:",
        "      - REJECT",
        "      - DIRECT",
        "",
        "  - name: ğŸŸ æ¼ç½‘ç­–ç•¥",
        "    type: select",
        "    proxies:",
        "      - ğŸ¯ å…¨çƒç›´è¿",
        "      - ğŸš€ æ‰‹åŠ¨é€‰æ‹©",
        "      - â™»ï¸ è‡ªåŠ¨é€‰æ‹©",
    ]
    path.write_text("\n".join(lines) + "\n", encoding="utf-8")


def write_geox_url_snippet(path: Path) -> None:
    """ç”Ÿæˆ geox-url ç‰‡æ®µï¼Œä¾¿äºç»§ç»­æ²¿ç”¨ v2ray-rules-datã€‚"""

    lines = [
        "# å¯é€‰ï¼šç»§ç»­æ²¿ç”¨ v2ray-rules-dat ä½œä¸º GEO åŸºç¡€æ•°æ®æºã€‚",
        "# è‹¥ä½ å·²åœ¨ä¸»é…ç½®è®¾ç½® geox-urlï¼Œåˆ™ä»¥ä¸»é…ç½®ä¸ºå‡†ã€‚",
        "",
        "geodata-mode: true",
        "geox-url:",
        "  geoip: https://raw.githubusercontent.com/Loyalsoldier/v2ray-rules-dat/release/geoip.dat",
        "  geosite: https://raw.githubusercontent.com/Loyalsoldier/v2ray-rules-dat/release/geosite.dat",
    ]
    path.write_text("\n".join(lines) + "\n", encoding="utf-8")


def write_readme(path: Path) -> None:
    """ç”Ÿæˆ clash ç›®å½•ä¸‹çš„ä½¿ç”¨è¯´æ˜æ–‡æ¡£ã€‚"""

    lines = [
        "# Clash / mihomo è‡ªå®šä¹‰è§„åˆ™è¿ç§»è¯´æ˜",
        "",
        "## è‡ªåŠ¨ç”Ÿæˆå‘½ä»¤",
        "",
        "```bash",
        "python3 scripts/generate_clash_rules.py",
        "```",
        "",
        "å¯é€‰å‚æ•°ç¤ºä¾‹ï¼š",
        "",
        "```bash",
        "python3 scripts/generate_clash_rules.py --repo novcky/v2rayCustomRoutingList --branch main --github-id 3379345",
        "```",
        "",
        "ä½¿ç”¨å¢å¼ºæ¨¡æ¿ï¼ˆä¿æŒè§„åˆ™æ¥æºä»ä¸º `custom_routing_rules`ï¼‰ï¼š",
        "",
        "```bash",
        "python3 scripts/generate_clash_rules.py --template-profile boost",
        "```",
        "",
        "å¯ç”¨ä¸¥æ ¼æ¨¡å¼ï¼ˆå‡ºç° warning æ—¶é€€å‡ºï¼Œé€‚åˆ CIï¼‰ï¼š",
        "",
        "```bash",
        "python3 scripts/generate_clash_rules.py --strict",
        "```",
        "",
        "å¦‚éœ€åªç”Ÿæˆè§„åˆ™ç‰‡æ®µï¼Œä¸ç”Ÿæˆè®¢é˜…ç«™æ¨¡æ¿ï¼š",
        "",
        "```bash",
        "python3 scripts/generate_clash_rules.py --no-template",
        "```",
        "",
        "## ç”Ÿæˆç»“æœ",
        "",
        "- `rules/*.yaml`ï¼šæŒ‰ `custom_routing_rules` é¡ºåºæ‹†åˆ†åçš„ rule-provider æ–‡ä»¶ã€‚",
        "- `mihomo-custom-rules.yaml`ï¼šä¸»ç‰‡æ®µï¼ŒåŒ…å« `proxy-groups`ã€`rule-providers` ä¸ `rules`ã€‚",
        "- `template.fake-ip.yaml`ï¼šå¯ç”¨äºè®¢é˜…ç«™æ¸²æŸ“çš„æ¨¡æ¿ï¼ˆå« `__PROXY_PROVIDERS__` / `__PROXY_NODES__` å ä½ç¬¦ï¼‰ã€‚",
        "- `proxy-groups-custom.example.yaml`ï¼šå¯é€‰åˆ†ç»„ç¤ºä¾‹ï¼ˆä¸æ¨¡æ¿åŒåç»„ï¼‰ã€‚",
        "- `geox-url-v2ray-rules-dat.yaml`ï¼šå¯é€‰ GEO æ•°æ®æºç‰‡æ®µã€‚",
        "",
        "## æ¥å…¥å»ºè®®ï¼ˆAndroid / PC é€šç”¨ï¼‰",
        "",
        "1. å°† `mihomo-custom-rules.yaml` åˆå¹¶åˆ°ä¸»é…ç½®ï¼ˆå†…å«ä¸æ¨¡æ¿åŒåçš„é»˜è®¤ç­–ç•¥ç»„ï¼‰ã€‚",
        "2. å°† `ğŸš€ æ‰‹åŠ¨é€‰æ‹©` / `â™»ï¸ è‡ªåŠ¨é€‰æ‹©` æ›¿æ¢ä¸ºä½ çš„çœŸå®ä»£ç†å…¥å£ã€‚",
        "3. å¦‚éœ€ç‹¬ç«‹ç»´æŠ¤ç­–ç•¥ç»„ï¼Œå¯å‚è€ƒ `proxy-groups-custom.example.yaml`ã€‚",
        "4. å¦‚éœ€ç»§ç»­æ²¿ç”¨ v2ray åŸºç¡€åº“ï¼Œå¯åˆå¹¶ `geox-url-v2ray-rules-dat.yaml`ã€‚",
        "",
        "## å…¼å®¹å·®å¼‚",
        "",
        "- `protocol:bittorrent` åœ¨ Clash æ— ç­‰ä»·è§„åˆ™ï¼Œè‡ªåŠ¨é™çº§ä¸º `GEOSITE,category-pt`ã€‚",
        "- è§„åˆ™å¯é€‰ `policyGroup` å­—æ®µå¯è¦†ç›–é»˜è®¤åˆ†ç»„æ˜ å°„ï¼›æœªè®¾ç½®æ—¶æŒ‰ outboundTag æ˜ å°„ã€‚",
        "- `--template-profile boost` ä»…å¢å¼ºæ¨¡æ¿è¿è¡Œå‚æ•°ï¼Œä¸å¼•å…¥å¤–éƒ¨è§„åˆ™æ–‡ä»¶ä¾èµ–ã€‚",
        "- çº¯ `0-65535` / `1-65535` å…¨ç«¯å£å…œåº•è§„åˆ™ä¼šè‡ªåŠ¨è½¬æ¢ä¸º `MATCH`ã€‚",
        "- è®¢é˜…ç«™æ¨¡æ¿ä¸­ï¼Œæœ«å°¾ `MATCH` é»˜è®¤æŒ‡å‘â€œæ¼ç½‘ç­–ç•¥â€ç»„ï¼Œä¾¿äºåœ¨å®¢æˆ·ç«¯ä¸€é”®åˆ‡æ¢ç›´è¿/ä»£ç†ã€‚",
        "- `enabled=false` æ¡ç›®ä¸ä¼šç”Ÿæˆ provider æ–‡ä»¶ä¸ provider å£°æ˜ï¼Œä»…ä¿ç•™æ³¨é‡Šæ–¹ä¾¿å›æ»šã€‚",
        "- remarks å†™â€œæ‹¦æˆªâ€ä½† outboundTag ä¸º `direct` çš„æ¡ç›®ï¼Œä¼šæŒ‰çœŸå®è¡Œä¸ºæ˜ å°„ä¸º `direct`ã€‚",
    ]
    path.write_text("\n".join(lines) + "\n", encoding="utf-8")


def append_template_dns(lines: list[str], template_profile: str) -> None:
    """å†™å…¥è®¢é˜…æ¨¡æ¿ DNS æ®µã€‚

    `boost` åœ¨å…¼å®¹åŸºçº¿ä¸Šè¿½åŠ å¢å¼ºé¡¹ï¼Œé¿å…å› ä¸ºé»˜è®¤å¼ºå¼€æ–°ç‰¹æ€§å¯¼è‡´æ—§å†…æ ¸åŠ è½½å¤±è´¥ã€‚
    """

    lines.append("dns:")
    lines.append("  enable: true")
    lines.append("  ipv6: true")
    lines.append("  respect-rules: true")
    lines.append("  enhanced-mode: fake-ip")
    lines.append("  nameserver:")
    lines.append("    - https://120.53.53.53/dns-query")
    lines.append("    - https://223.5.5.5/dns-query")
    lines.append("  proxy-server-nameserver:")
    lines.append("    - https://120.53.53.53/dns-query")
    lines.append("    - https://223.5.5.5/dns-query")
    lines.append("  nameserver-policy:")
    lines.append("    geosite:cn,private:")
    lines.append("      - https://120.53.53.53/dns-query")
    lines.append("      - https://223.5.5.5/dns-query")
    lines.append("    geosite:geolocation-!cn:")
    lines.append("      - https://dns.cloudflare.com/dns-query")
    lines.append("      - https://dns.google/dns-query")

    if template_profile != "boost":
        return

    lines.append("  listen: 127.0.0.1:5335")
    lines.append("  use-system-hosts: false")
    lines.append("  fake-ip-range: 198.18.0.1/16")
    lines.append("  default-nameserver:")
    lines.append("    - 223.5.5.5")
    lines.append("    - 119.29.29.29")
    lines.append("    - 1.1.1.1")
    lines.append("    - 8.8.8.8")
    lines.append("  fallback:")
    lines.append("    - https://dns.google/dns-query")
    lines.append("    - https://cloudflare-dns.com/dns-query")
    lines.append("  fallback-filter:")
    lines.append("    geoip: true")
    lines.append("    ipcidr:")
    lines.append("      - 240.0.0.0/4")
    lines.append("      - 0.0.0.0/32")
    lines.append("      - 127.0.0.1/32")
    lines.append("    domain:")
    lines.append("      - +.google.com")
    lines.append("      - +.googleapis.com")
    lines.append("      - +.gvt1.com")
    lines.append("      - +.youtube.com")
    lines.append("  fake-ip-filter:")
    lines.append("    - *.lan")
    lines.append("    - localhost")
    lines.append("    - time.windows.com")
    lines.append("    - time.apple.com")
    lines.append("    - time.google.com")


def append_template_runtime(lines: list[str], template_profile: str) -> None:
    """å†™å…¥è®¢é˜…æ¨¡æ¿è¿è¡Œæ—¶å¢å¼ºé…ç½®ã€‚"""

    if template_profile != "boost":
        return

    lines.append("unified-delay: true")
    lines.append("tcp-concurrent: true")
    lines.append("find-process-mode: strict")
    lines.append("sniffer:")
    lines.append("  enable: true")
    lines.append("  parse-pure-ip: true")
    lines.append("  sniff:")
    lines.append("    TLS: {ports: [443, 8443]}")
    lines.append("    HTTP: {ports: [80, 8080-8880], override-destination: true}")
    lines.append("    QUIC: {ports: [443, 8443]}")
    lines.append("geodata-mode: true")
    lines.append("geo-auto-update: true")
    lines.append("geo-update-interval: 24")


def write_subscription_template(
    path: Path,
    rules: list[ConvertedRule],
    repo: str,
    branch: str,
    interval: int,
    github_id: str,
    template_profile: str,
) -> None:
    """ç”Ÿæˆè®¢é˜…ç«™ fake-ip æ¨¡æ¿ã€‚

    æ¨¡æ¿ä¸ä¸»ç‰‡æ®µå…±äº«åŒä¸€å¥—è§„åˆ™è¯­ä¹‰ï¼Œä½†åŒ…å«è®¢é˜…ç«™å ä½ç¬¦ä¸æ›´å®Œæ•´çš„ DNS åŸºç¡€æ®µã€‚
    """

    # å‚æ•°ä¿ç•™ï¼šæ¨¡æ¿å½“å‰ä¸ç›´æ¥æ‹¼ icon URLï¼Œä¿ç•™ç­¾åä¾¿äºåç»­æ— ç ´åæ‰©å±•ã€‚
    _ = github_id
    # æ¨¡æ¿é»˜è®¤ä½¿ç”¨å›ºå®šåˆ†ç»„åï¼Œç¡®ä¿è®¢é˜…ç«™æ¸²æŸ“å‰åå‘½åç¨³å®šï¼Œä¸å½±å“è§„åˆ™å¼•ç”¨ã€‚
    proxy_group = "ğŸš€ æ‰‹åŠ¨é€‰æ‹©"
    auto_group = "â™»ï¸ è‡ªåŠ¨é€‰æ‹©"
    direct_group = "ğŸ¯ å…¨çƒç›´è¿"
    block_group = "â›” å¼ºåˆ¶é˜»æ–­"
    fallback_group = "ğŸŸ æ¼ç½‘ç­–ç•¥"
    builtin_groups = {proxy_group, auto_group, direct_group, block_group, fallback_group}
    custom_policy_groups = collect_custom_policy_groups(rules, builtin_groups)

    lines: list[str] = []
    lines.append("# è®¢é˜…ç«™æ¨¡æ¿ï¼šç”± scripts/generate_clash_rules.py è‡ªåŠ¨ç”Ÿæˆã€‚")
    lines.append("# è¯´æ˜ï¼š")
    lines.append("# 1) `__PROXY_PROVIDERS__` ä¸ `__PROXY_NODES__` ç”±è®¢é˜…ç«™åœ¨æ¸²æŸ“é˜¶æ®µæ›¿æ¢ã€‚")
    lines.append("# 2) è‡ªå®šä¹‰è§„åˆ™é¡ºåºæ¥è‡ª custom_routing_rulesï¼Œå¹¶æŒ‰åŸ enabled çŠ¶æ€è¾“å‡ºã€‚")
    lines.append("# 3) æœ«å°¾ MATCH å›ºå®šä½¿ç”¨â€œæ¼ç½‘ç­–ç•¥â€ç»„ï¼Œæ–¹ä¾¿åœ¨å®¢æˆ·ç«¯ä¸€é”®åˆ‡æ¢ç›´è¿/ä»£ç†ã€‚")
    lines.append(f"# 4) å½“å‰æ¨¡æ¿æ¡£ä½ï¼š{template_profile}ã€‚")
    lines.append("")
    lines.append("port: 7890")
    lines.append("socks-port: 7891")
    lines.append("allow-lan: true")
    lines.append("mode: rule")
    lines.append("log-level: info")
    append_template_runtime(lines, template_profile)
    lines.append("external-controller: 127.0.0.1:9090")
    append_template_dns(lines, template_profile)
    lines.append("proxies: null")
    lines.append("proxy-groups:")
    lines.append(f"  - name: {proxy_group}")
    lines.append("    type: select")
    lines.append("    include-all: true")
    lines.append("    include-all-proxies: true")
    lines.append("    include-all-providers: true")
    lines.append("    proxies:")
    lines.append(f"      - {auto_group}")
    lines.append("      - __PROXY_PROVIDERS__")
    lines.append("      - __PROXY_NODES__")
    lines.append(f"  - name: {auto_group}")
    lines.append("    type: url-test")
    lines.append("    include-all: true")
    lines.append("    include-all-proxies: true")
    lines.append("    include-all-providers: true")
    lines.append("    proxies:")
    lines.append("      - __PROXY_PROVIDERS__")
    lines.append("      - __PROXY_NODES__")
    lines.append("    url: https://cp.cloudflare.com/generate_204")
    lines.append("    interval: 300")
    lines.append("    tolerance: 50")
    lines.append(f"  - name: {direct_group}")
    lines.append("    type: select")
    lines.append("    proxies:")
    lines.append("      - DIRECT")
    lines.append(f"  - name: {block_group}")
    lines.append("    type: select")
    lines.append("    proxies:")
    lines.append("      - REJECT")
    lines.append("      - DIRECT")
    for group_name in custom_policy_groups:
        # æ‰©å±•åˆ†ç»„ç”± custom_routing_rules çš„ policyGroup å£°æ˜é©±åŠ¨ï¼Œé¿å…æ¨¡æ¿å†…å†™æ­»ä¸šåŠ¡åˆ†ç»„ã€‚
        lines.append(f"  - name: {group_name}")
        lines.append("    type: select")
        lines.append("    include-all: true")
        lines.append("    include-all-proxies: true")
        lines.append("    include-all-providers: true")
        lines.append("    proxies:")
        lines.append(f"      - {proxy_group}")
        lines.append(f"      - {auto_group}")
        lines.append(f"      - {direct_group}")
        lines.append(f"      - {block_group}")
        lines.append("      - __PROXY_PROVIDERS__")
        lines.append("      - __PROXY_NODES__")
    lines.append(f"  - name: {fallback_group}")
    lines.append("    type: select")
    lines.append("    include-all: true")
    lines.append("    include-all-proxies: true")
    lines.append("    include-all-providers: true")
    lines.append("    proxies:")
    lines.append(f"      - {direct_group}")
    lines.append(f"      - {proxy_group}")
    lines.append(f"      - {auto_group}")
    lines.append("      - __PROXY_PROVIDERS__")
    lines.append("      - __PROXY_NODES__")
    lines.append("rules:")
    has_terminal_match = False
    for rule in rules:
        policy_group = resolve_policy_group(rule, proxy_group, direct_group, block_group)
        lines.append(f"  # {rule.index:02d} {rule.remarks}")
        if rule.is_match_all:
            if not rule.enabled:
                lines.append("  # åŸè§„åˆ™ enabled=falseï¼Œé»˜è®¤ä¿æŒç¦ç”¨ã€‚")
                lines.append(f"  # - MATCH,{fallback_group}")
                continue
            lines.append(f"  - MATCH,{fallback_group}")
            has_terminal_match = True
            continue
        if not rule.enabled:
            lines.append("  # åŸè§„åˆ™ enabled=falseï¼Œé»˜è®¤ä¿æŒç¦ç”¨ã€‚")
            lines.append(f"  # - RULE-SET,{rule.provider_name},{policy_group}")
            continue
        lines.append(f"  - RULE-SET,{rule.provider_name},{policy_group}")
    if not has_terminal_match:
        lines.append(f"  - MATCH,{fallback_group}")
    # æ¨¡æ¿ä¸­çš„ provider è·¯å¾„ä½¿ç”¨ `./providers/custom/`ï¼Œä¸å¸¸è§è®¢é˜…ç«™ç›®å½•ç»“æ„å…¼å®¹ã€‚
    lines.append("rule-providers:")
    for rule in rules:
        if rule.is_match_all or not rule.enabled:
            continue
        lines.append(f"  {rule.provider_name}:")
        lines.append("    type: http")
        lines.append("    behavior: classical")
        lines.append("    format: yaml")
        lines.append(
            f"    url: https://raw.githubusercontent.com/{repo}/{branch}/clash/rules/{rule.file_name}"
        )
        lines.append(f"    path: ./providers/custom/{rule.file_name}")
        lines.append(f"    interval: {interval}")

    path.write_text("\n".join(lines) + "\n", encoding="utf-8")


def cleanup_generated_rule_files(rules_dir: Path) -> None:
    """æ¸…ç†æ—§çš„è‡ªåŠ¨ç”Ÿæˆ rule æ–‡ä»¶ã€‚

    ä»…åˆ é™¤ç¬¦åˆâ€œåºå·-åç§°â€æ ¼å¼çš„æ–‡ä»¶ï¼Œé¿å…è¯¯åˆ ç”¨æˆ·æ‰‹å·¥ç»´æŠ¤çš„è‡ªå®šä¹‰è§„åˆ™æ–‡ä»¶ã€‚
    """

    # ä»…æ¸…ç†â€œåºå·å‰ç¼€â€çš„ç”Ÿæˆäº§ç‰©ï¼Œé¿å…è¯¯åˆ ç”¨æˆ·æ‰‹å·¥ç»´æŠ¤çš„å…¶å®ƒæ–‡ä»¶ã€‚
    pattern = re.compile(r"^\d{2}-.+\.ya?ml$")
    for file_path in rules_dir.glob("*.y*ml"):
        if pattern.match(file_path.name):
            try:
                file_path.unlink()
            except FileNotFoundError:
                # å¹¶å‘ç”Ÿæˆæ—¶æ–‡ä»¶å¯èƒ½å·²è¢«å¦ä¸€è¿›ç¨‹åˆ æ‰ï¼Œè¿™é‡ŒæŒ‰â€œå·²æ¸…ç†â€å¤„ç†å³å¯ã€‚
                continue


def main() -> int:
    """è„šæœ¬ä¸»æµç¨‹ï¼šè¯»å–æºè§„åˆ™ -> è½¬æ¢ -> å†™å…¥å„ç±»äº§ç‰©ã€‚"""

    args = parse_args()
    project_root = Path(__file__).resolve().parent.parent
    input_path = (project_root / args.input).resolve()
    output_dir = (project_root / args.output_dir).resolve()

    if not input_path.exists():
        print(f"[ERROR] æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶: {input_path}", file=sys.stderr)
        return 1

    # ä¼˜å…ˆä½¿ç”¨æ˜¾å¼å‚æ•°ï¼›ä¸ºç©ºæ—¶å†å›é€€åˆ° git remote æ¨æ–­ï¼Œå‡å°‘ CI/ç¦»çº¿ç¯å¢ƒå¤±è´¥æ¦‚ç‡ã€‚
    repo = args.repo.strip() or infer_repo_slug(project_root)
    if not repo:
        print(
            "[ERROR] æ— æ³•ä» git remote æ¨æ–­ä»“åº“ï¼Œè¯·é€šè¿‡ --repo owner/repo æ˜¾å¼ä¼ å…¥ã€‚",
            file=sys.stderr,
        )
        return 1

    source_rules = load_source_rules(input_path)
    validation_errors, validation_warnings = validate_source_rules(source_rules)
    if validation_errors:
        print("[ERROR] æºè§„åˆ™æ ¡éªŒå¤±è´¥ï¼š", file=sys.stderr)
        for item in validation_errors:
            print(f"  - {item}", file=sys.stderr)
        return 1

    used_slugs: set[str] = set()
    converted: list[ConvertedRule] = []
    all_warnings: list[str] = [f"[validate] {item}" for item in validation_warnings]

    for idx, src_rule in enumerate(source_rules, 1):
        rule = convert_rule(idx, src_rule, used_slugs)
        converted.append(rule)
        for warning in rule.warnings:
            all_warnings.append(f"#{idx:02d} {rule.remarks}: {warning}")

    if args.strict and all_warnings:
        print("[ERROR] strict æ¨¡å¼å‘½ä¸­ warningï¼Œå·²ç»ˆæ­¢ç”Ÿæˆï¼š", file=sys.stderr)
        for item in all_warnings:
            print(f"  - {item}", file=sys.stderr)
        return 2

    rules_dir = output_dir / "rules"
    rules_dir.mkdir(parents=True, exist_ok=True)
    # å…ˆåˆ åå†™å¯é¿å…é‡å‘½ååç•™ä¸‹â€œæ—§ provider æ–‡ä»¶â€è¢«è¯¯å¼•ç”¨ã€‚
    cleanup_generated_rule_files(rules_dir)
    for rule in converted:
        if rule.enabled and not rule.is_match_all:
            write_rule_file(rules_dir / rule.file_name, rule)

    write_main_file(
        path=output_dir / "mihomo-custom-rules.yaml",
        rules=converted,
        repo=repo,
        branch=args.branch,
        interval=args.interval,
        github_id=args.github_id,
    )
    if not args.no_template:
        write_subscription_template(
            path=output_dir / args.template_file,
            rules=converted,
            repo=repo,
            branch=args.branch,
            interval=args.interval,
            github_id=args.github_id,
            template_profile=args.template_profile,
        )
    write_proxy_group_example(output_dir / "proxy-groups-custom.example.yaml", args.github_id)
    write_geox_url_snippet(output_dir / "geox-url-v2ray-rules-dat.yaml")
    write_readme(output_dir / "README.md")

    print(f"[OK] å·²ç”Ÿæˆ {len(converted)} æ¡è§„åˆ™åˆ°: {output_dir}")
    if all_warnings:
        # warning è¾“å‡ºåˆ° stderrï¼Œä¾¿äºåœ¨ CI ä¸­ä¸æ­£å¸¸æ—¥å¿—åˆ†æµé‡‡é›†ã€‚
        print("[WARN] éœ€è¦äººå·¥å…³æ³¨çš„è¿ç§»é¡¹ï¼š", file=sys.stderr)
        for item in all_warnings:
            print(f"  - {item}", file=sys.stderr)

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
